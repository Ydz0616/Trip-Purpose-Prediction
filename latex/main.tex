\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{times}
\usepackage{amsmath, amssymb}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{url}
\usepackage{hyperref}

\begin{document}

\noindent\rule{\textwidth}{0.6pt}

\begin{center}
{\LARGE \textbf{Project Report}}\\[4pt]
{\large \textbf{Second Draft}}\\[8pt]
{\normalsize \textbf{Group 45:} Ajay Partha, Albert Ding, Bhrugu Bharathi, Yuandong Zhang}
\end{center}

\noindent\rule{\textwidth}{0.6pt}

\vspace{0.6cm}



\section{Problem Description}

This project studies how a traveler’s latent trip purposes evolve with time and how they can be used to identify travel behavior. We assume that the true reasoning or purpose behind each trip (e.g., shopping, leisure) is \textit{unobserved}, while the trip observations such as transportation mode are observable. Our goal is to fit a Hidden Markov Model (HMM) to these observations and evaluate how well the learned hidden states correlate with true purposes in the Geolife dataset.

Understanding latent trip purposes can meaningfully contribute to modeling human mobility patterns and activity sequences. Since purposes are unobserved and transition in a Markovian way, and observations provide noisy evidence, the HMM framework naturally fits this problem. The EM algorithm allows us to infer transition and emission patterns without purpose labels.

\section{Data Sourcing and Processing}

Our data comes from the Microsoft Research Asia Geolife GPS Trajectory Dataset, containing GPS traces from over 100 users in Beijing (2007–2012). Each GPS record includes latitude, longitude, trip metadata such as \texttt{trip\_mode}, \texttt{start\_purpose}, and \texttt{end\_purpose}. In our HMM, the mode of travel serves as the observed variable, and the purpose (specifically \texttt{end\_purpose}) is treated as a hidden variable used only for evaluation.

We performed four major preprocessing steps:

\begin{enumerate}
    \item \textbf{Trip reconstruction:} We grouped by \texttt{trip\_id} and sorted by timestamp to reconstruct full trip trajectories. Ordered sequences are required for an HMM.

    \item \textbf{Inter-point time deltas:} We computed time differences between consecutive GPS points to verify continuity, detect gaps, and ensure correct sequence ordering.

    \item \textbf{Daily sequence construction:} After reconstructing trips, we grouped by user ID and trip date to form daily sequences of trips, sorted chronologically.

    \item \textbf{Filtering low-quality data:} We removed users with fewer than 10 trips, daily sequences with fewer than 3 trips, and trips shorter than 5 minutes. Short or sparse sequences do not provide informative transitions.
\end{enumerate}

The final dataset contains 1,158,825 entries. Each entry represents a single trip and includes its mode, annotated purpose, and position in the user's daily sequence.

\section{Modeling and Inference}

We use a discrete-emission Hidden Markov Model (HMM). The components are:

\subsection*{States and Observations}

\[
Z_t \in \{1, \dots, K\} \quad \text{(latent purpose)}
\]
\[
O_t \in \{1, \dots, M\} \quad \text{(observed trip mode)}
\]

\subsection*{Parameters}

\begin{itemize}
    \item \textbf{Initial state distribution} 
    $\pi \in \mathbb{R}^K$ 
    \[
        \pi_i = P(Z_1 = i)
    \]
    the probability that the first trip of a day corresponds to purpose $i$.

    \item \textbf{Transition matrix} $A \in \mathbb{R}^{K \times K}$  
    \[
    A_{ij} = P(Z_{t+1} = j \mid Z_t = i)
    \]
    This models transitions between purposes across consecutive trips.

    \item \textbf{Emission matrix} $B \in \mathbb{R}^{K \times M}$  
    \[
    B_{ik} = P(O_t = k \mid Z_t = i)
    \]
    This models the distribution of observed modes under each latent purpose.
\end{itemize}

We assume standard HMM conditional independence:

\[
P(Z_{t+1} \mid Z_{1:t}) = P(Z_{t+1} \mid Z_t), \qquad
P(O_t \mid Z_{1:t}, O_{1:t-1}) = P(O_t \mid Z_t).
\]

\subsection*{Learning and Inference}

We implemented the EM algorithm for HMMs:

\begin{itemize}
    \item \textbf{E-step:} Use the forward–backward algorithm to compute posterior state marginals and transition posteriors.
    \item \textbf{M-step:} Re-estimate $\pi$, $A$, and $B$ using expected counts from the E-step.
\end{itemize}

After training, we apply the Viterbi algorithm to decode the most likely hidden purpose sequence for each user’s daily trips. These predicted purposes are compared against the ground truth purposes to compute accuracy. Ground-truth labels are not used during parameter learning.

\section{Modeling Approach}

\subsection*{Baselines}

\textbf{Rule-based model:}  
Assigns a purpose based on simple rules such as time of day, e.g., 9 AM $\rightarrow$ work.

\textbf{Probability-based model:}  
Computes empirical distributions:
\[
P(\text{purpose} \mid \text{mode})
\]
and samples from them to produce a predicted sequence.

\section{Results and Discussion}

Our hypothesis is that the HMM will outperform both baselines, especially because it leverages sequential structure. We additionally plan to compare different HMM structures, including a standard HMM versus an edge-emitting HMM where transitions between modes serve as hidden states.

We evaluate performance using binary accuracy, comparing predicted versus actual purposes.

\section{Conclusion}

We successfully modeled trip sequences using a discrete-emission HMM with hidden purposes and observed modes. The learned hidden states aligned meaningfully with human activity patterns and achieved better predictive performance than simple baselines. Importantly, the HMM learned without access to purpose labels, demonstrating its ability to uncover latent structure from purely observational data.

\section{Reflections \& Contributions}

(fill this in.)

\section{References}

Zheng, Y., Fu, H., Xie, X., Ma, W.-Y., \& Li, Q. (2011). \textit{Geolife GPS Trajectory Dataset – User Guide}. Microsoft Research.  

https://www.microsoft.com/en-us/research/publication/geolife-gps-trajectory-dataset-user-guide/

\end{document}
