{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5104e990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.preprocessing import load_and_process_data, create_user_sequences, train_test_split_by_user\n",
    "from src.hmm import HiddenMarkovModel, ThreeGramHiddenMarkovModel\n",
    "from src.baselines import TimeOfDayBaseline, FrequencyBaseline\n",
    "from src.utils import LabelEncoder, calculate_accuracy\n",
    "from src.baselines import TimeOfDayBaseline, FrequencyBaseline,RFBaseline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe9e700",
   "metadata": {},
   "source": [
    "**DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "432041ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/mode_purpose_hmm.csv\" # Adjust path if necessary\n",
    "df = load_and_process_data(data_path)\n",
    "user_sequences = create_user_sequences(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f7c901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqs, test_seqs = train_test_split_by_user(user_sequences, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bfeb8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('car', 'errand', Timestamp('2021-08-04 19:22:46+0000', tz='UTC')), ('walk', 'home', Timestamp('2021-08-04 21:03:32+0000', tz='UTC')), ('car', 'home', Timestamp('2021-08-04 21:33:50+0000', tz='UTC'))]\n"
     ]
    }
   ],
   "source": [
    "# sample entry\n",
    "print(train_seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d145be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode data\n",
    "mode_encoder = LabelEncoder()\n",
    "purpose_encoder = LabelEncoder()\n",
    "\n",
    "all_modes = set()\n",
    "all_purposes = set()\n",
    "\n",
    "for seq in train_seqs+test_seqs:\n",
    "    for mode,purpose,_ in seq:\n",
    "        all_modes.add(mode)\n",
    "        all_purposes.add(purpose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dafc43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_encoder.fit(list(all_modes))\n",
    "purpose_encoder.fit(list(all_purposes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e52f5b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modes: ['bike', 'bus', 'car', 'train', 'walk']\n",
      "Purposes: ['eat', 'errand', 'home', 'leisure', 'work']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Modes: {mode_encoder.classes_}\")\n",
    "print(f\"Purposes: {purpose_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94344a68",
   "metadata": {},
   "source": [
    "**BASELINE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b1552d",
   "metadata": {},
   "source": [
    "***Rule-based***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6422f04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeOfDay Baseline Accuracy: 0.2092\n"
     ]
    }
   ],
   "source": [
    "# rule-based, predict purpose given time of day\n",
    "\n",
    "tod_baseline = TimeOfDayBaseline()\n",
    "\n",
    "tod_true = []\n",
    "tod_pred = []\n",
    "\n",
    "for seq in test_seqs:\n",
    "    for _,gt_purpose, timestamp in seq:\n",
    "        tod_true.append(gt_purpose)\n",
    "        pred = tod_baseline.predict(timestamp)\n",
    "        tod_pred.append(pred)\n",
    "\n",
    "acc_tod = accuracy_score(tod_true, tod_pred)\n",
    "print(f\"TimeOfDay Baseline Accuracy: {acc_tod:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c67db9",
   "metadata": {},
   "source": [
    "***Frequency-based***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c48db71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency Baseline Accuracy: 0.2722\n"
     ]
    }
   ],
   "source": [
    "freq_baseline = FrequencyBaseline()\n",
    "\n",
    "# get mode and purpose, w/o timestamps\n",
    "train_seqs_stripped = [[(row[0], row[1]) for row in seq] for seq in train_seqs]\n",
    "\n",
    "# training\n",
    "freq_baseline.fit(train_seqs_stripped)\n",
    "\n",
    "freq_true_flattened = []\n",
    "freq_pred_flattened = []\n",
    "\n",
    "# prediction\n",
    "for seq in test_seqs:\n",
    "    for row in seq:\n",
    "        mode, true_purpose, _ = row  \n",
    "        \n",
    "        pred_purpose = freq_baseline.predict(mode)\n",
    "        \n",
    "        freq_true_flattened.append(true_purpose)\n",
    "        freq_pred_flattened.append(pred_purpose)\n",
    "\n",
    "acc_freq = accuracy_score(freq_true_flattened, freq_pred_flattened)\n",
    "print(f\"Frequency Baseline Accuracy: {acc_freq:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a33db28",
   "metadata": {},
   "source": [
    "***Random Forest***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6230c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rf_data(sequences, m_encoder, p_encoder):\n",
    "    \"\"\"\n",
    "    convert (mode,purpose,timestamp) to X= [mode,timestamp], y = [purpose]\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for seq in sequences: # daily trips \n",
    "        for row in seq: # one trip with mode, purpose, time \n",
    "            mode, purpose, timestamp = row\n",
    "            \n",
    "            # feature 1 :mode of the trip \n",
    "            m_idx = m_encoder.transform([mode])[0]\n",
    "            \n",
    "            # feature 2: hour of day \n",
    "            hour = timestamp.hour\n",
    "            \n",
    "            X.append([m_idx, hour])\n",
    "            \n",
    "            # gt purpose \n",
    "            p_idx = p_encoder.transform([purpose])[0]\n",
    "            y.append(p_idx)\n",
    "            \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f7388de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_rf_data(train_seqs, mode_encoder, purpose_encoder)\n",
    "X_test, y_test = prepare_rf_data(test_seqs, mode_encoder, purpose_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c16773b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 19]\n"
     ]
    }
   ],
   "source": [
    "# sample X train\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "798f8f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_baseline = RFBaseline(n_estimators=300,random_seed=42)\n",
    "rf_baseline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "837ba003",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_baseline.predict(X_test)\n",
    "y_test_label = purpose_encoder.inverse_transform(y_test)\n",
    "y_pred_label = purpose_encoder.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80cf1f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.4617\n"
     ]
    }
   ],
   "source": [
    "acc_rf = accuracy_score(y_test_label, y_pred_label)\n",
    "print(f\"Random Forest Accuracy: {acc_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8b7a10",
   "metadata": {},
   "source": [
    "***Standard 1-Gram HMM***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6f0c249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM Accuracy: 0.3561\n"
     ]
    }
   ],
   "source": [
    "# HMM Model\n",
    "hmm = HiddenMarkovModel(num_states=len(purpose_encoder), num_observations=len(mode_encoder))\n",
    "\n",
    "# Train (MLE)\n",
    "hmm.maximum_likelihood_initialize_parameters(train_seqs, purpose_encoder, mode_encoder)\n",
    "\n",
    "# Predict (Viterbi)\n",
    "true_purposes = []\n",
    "pred_purposes = []\n",
    "\n",
    "for i, seq in enumerate(test_seqs):\n",
    "    # Extract modes and purposes\n",
    "    modes = [row[0] for row in seq]\n",
    "    purposes = [row[1] for row in seq]\n",
    "    \n",
    "    # Encode modes to integers\n",
    "    obs_seq = mode_encoder.transform(modes)\n",
    "    \n",
    "    # Predict\n",
    "    pred_indices = hmm.predict_viterbi(obs_seq)\n",
    "    \n",
    "    # Decode predictions\n",
    "    pred_labels = purpose_encoder.inverse_transform(pred_indices)\n",
    "    \n",
    "    true_purposes.append(purposes)\n",
    "    pred_purposes.append(pred_labels)\n",
    "    # print(purposes)\n",
    "    # print(pred_labels)\n",
    "    # print(\"======\")\n",
    "    # if i == 10:\n",
    "    #     break\n",
    "    \n",
    "\n",
    "# Accuracy\n",
    "acc_hmm = calculate_accuracy(true_purposes, pred_purposes)\n",
    "print(f\"HMM Accuracy: {acc_hmm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ffed4b",
   "metadata": {},
   "source": [
    "While this attempt performs better than the rule-based and frequency-based baselines, it is still not as good as the Random Forest model. Upon observation of some of the predictions/labels, it seems that the HMM model is biased towards state transitions that reach the \"home\" purpose. This may be fixed with a higher-order HMM model. If not, then we may need to clean the data or make the number of purposes more granular."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f94538",
   "metadata": {},
   "source": [
    "***3-Gram HMM***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "017b4334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Gram HMM Accuracy: 0.3240\n"
     ]
    }
   ],
   "source": [
    "# 3-Gram HMM Model\n",
    "hmm3 = ThreeGramHiddenMarkovModel(num_states=len(purpose_encoder), num_observations=len(mode_encoder))\n",
    "\n",
    "# Train (MLE)\n",
    "hmm3.maximum_likelihood_initialize_parameters(train_seqs, purpose_encoder, mode_encoder)\n",
    "\n",
    "# Predict (Viterbi)\n",
    "true_purposes_3 = []\n",
    "pred_purposes_3 = []\n",
    "\n",
    "for i, seq in enumerate(test_seqs):\n",
    "    # Extract modes and purposes\n",
    "    modes = [row[0] for row in seq]\n",
    "    purposes = [row[1] for row in seq]\n",
    "    \n",
    "    # Encode modes to integers\n",
    "    obs_seq = mode_encoder.transform(modes)\n",
    "    \n",
    "    # Predict\n",
    "    pred_indices = hmm3.predict_viterbi(obs_seq)\n",
    "    \n",
    "    # Decode predictions\n",
    "    pred_labels = purpose_encoder.inverse_transform(pred_indices)\n",
    "    \n",
    "    true_purposes_3.append(purposes)\n",
    "    pred_purposes_3.append(pred_labels)\n",
    "\n",
    "# Accuracy\n",
    "acc_hmm3 = calculate_accuracy(true_purposes_3, pred_purposes_3)\n",
    "print(f\"3-Gram HMM Accuracy: {acc_hmm3:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
